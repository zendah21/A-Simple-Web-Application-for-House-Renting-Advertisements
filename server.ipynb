{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDfIWY55ftxe1xXKMJ9ua2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zendah21/A-Simple-Web-Application-for-House-Renting-Advertisements/blob/master/server.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cLhU9Y2sQ_Qk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7P-uqDJSQt9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35aec24b-3b55-4689-91ba-2fdc0a25156e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold, train_test_split\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "r3fOeCLLP6ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Constants\n",
        "IMAGE_SIZE = (128, 128)\n",
        "OVERSAMPLING_STRATEGY = \"minority\"\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "\n",
        "\n",
        "def get_pixel(img, center, x, y):\n",
        "    try:\n",
        "        return 1 if img[x][y] >= center else 0\n",
        "    except IndexError:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def lbp_calculated_pixel(img, x, y):\n",
        "    center = img[x][y]\n",
        "    val_ar = [\n",
        "        get_pixel(img, center, x - 1, y - 1),\n",
        "        get_pixel(img, center, x - 1, y),\n",
        "        get_pixel(img, center, x - 1, y + 1),\n",
        "        get_pixel(img, center, x, y + 1),\n",
        "        get_pixel(img, center, x + 1, y + 1),\n",
        "        get_pixel(img, center, x + 1, y),\n",
        "        get_pixel(img, center, x + 1, y - 1),\n",
        "        get_pixel(img, center, x, y - 1)\n",
        "    ]\n",
        "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
        "    return sum(val_ar[i] * power_val[i] for i in range(len(val_ar)))\n",
        "\n",
        "\n",
        "def plot_dataset_distribution(labels, title):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(labels, bins=2, color=['blue', 'green'], edgecolor='black')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Class Label')\n",
        "    plt.ylabel('Number of Samples')\n",
        "    plt.xticks([0, 1], ['Unhealthy', 'Healthy'])\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def calculate_lbp_features(image):\n",
        "    rows, cols = image.shape\n",
        "    lbp_values = np.zeros_like(image, dtype=np.uint8)\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            lbp_values[i, j] = lbp_calculated_pixel(image, i, j)\n",
        "\n",
        "    return lbp_values.flatten()\n",
        "\n",
        "\n",
        "def extract_lbp_features(file_path):\n",
        "    try:\n",
        "        image = cv2.imread(file_path)\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        gray_image = cv2.resize(gray_image, IMAGE_SIZE)\n",
        "        lbp_features = calculate_lbp_features(gray_image)\n",
        "        return lbp_features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_dataset(folder_path, label):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            lbp_features = extract_lbp_features(file_path)\n",
        "\n",
        "            if lbp_features is not None:\n",
        "                features.append(lbp_features)\n",
        "                labels.append(label)\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "def load_all_features_and_labels(folder_paths):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    total_images = 0\n",
        "\n",
        "    for folder_path in folder_paths:\n",
        "        print(f\"Processing folder: {folder_path}\")\n",
        "        num_images_in_folder = sum(1 for _ in os.listdir(folder_path) if _.lower().endswith(('.png', '.jpg', '.jpeg')))\n",
        "        total_images += num_images_in_folder\n",
        "        label = 1 if \"healthy\" in folder_path.lower() else 0\n",
        "        features, labels = load_dataset(folder_path, label)\n",
        "        all_features.extend(features)\n",
        "        all_labels.extend(labels)\n",
        "\n",
        "    print(f\"Total number of images: {total_images}\")\n",
        "    return all_features, all_labels\n",
        "\n",
        "\n",
        "def train_knn_model(features, labels, n_neighbors=3, weights='distance', metric='euclidean', test_size=0.2, cv=5,\n",
        "                    random_state=RANDOM_STATE):\n",
        "    print(f\"n_neighbors={n_neighbors}, weights={weights}, metric={metric}\")\n",
        "\n",
        "    # Display the distribution of the dataset before oversampling\n",
        "    plot_dataset_distribution(labels, 'Distribution Before SMOTE')\n",
        "\n",
        "    # Oversampled the features to be between -1 and 1\n",
        "    smote = SMOTE(sampling_strategy=OVERSAMPLING_STRATEGY, random_state=random_state)\n",
        "    features, labels = smote.fit_resample(features, labels)\n",
        "\n",
        "    # Display the distribution of the dataset after oversampling\n",
        "    plot_dataset_distribution(labels, 'Distribution After SMOTE')\n",
        "\n",
        "    # Standardize the features\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(np.array(features))\n",
        "\n",
        "    # Display the distribution of the dataset after standardization\n",
        "    plot_dataset_distribution(labels, 'Distribution After Standardization')\n",
        "\n",
        "    # Initialize KNN model\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric)\n",
        "\n",
        "    # Stratified K-Fold cross-validation\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
        "\n",
        "    # Split the data into training and testing sets before oversampling\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size,\n",
        "                                                        random_state=random_state)\n",
        "\n",
        "    # Cross-validated scores\n",
        "    cross_val_scores = cross_val_score(knn_model, X_train, y_train, cv=skf)\n",
        "\n",
        "    print(f\"Cross-Validation Scores: {cross_val_scores}\")\n",
        "    print(f\"Mean Cross-Validation Score: {np.mean(cross_val_scores):.2f}\")\n",
        "\n",
        "    # Train the KNN model on the entire resampled and standardized training set\n",
        "    knn_model.fit(X_train, y_train)\n",
        "\n",
        "    display_model_performance(knn_model, X_test, y_test)\n",
        "\n",
        "    return knn_model, scaler\n",
        "\n",
        "\n",
        "def display_model_performance(knn_model, X_test_normalized, y_test):\n",
        "    y_prediction = knn_model.predict(X_test_normalized)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_prediction))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_prediction))\n",
        "    accuracy = knn_model.score(X_test_normalized, y_test)\n",
        "    print(f\"\\nAccuracy: {accuracy:.2f}\")\n",
        "\n",
        "\n",
        "def save_model_and_scaler(knn_model, scaler, model_filename='knn_model_3.pkl', scaler_filename='scaler.pkl'):\n",
        "    try:\n",
        "        joblib.dump(knn_model, model_filename)\n",
        "        joblib.dump(scaler, scaler_filename)\n",
        "        print(f\"Model and scaler saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model and scaler: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "-J530RY-P3D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "folder_paths = [\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Apple___Apple_scab',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Apple___healthy',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Corn___healthy',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Corn___Common_rust',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Pepper,_bell___Bacterial_spot',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Pepper,_bell___healthy',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Potato___Early_blight',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Potato___healthy',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Tomato___healthy',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Tomato___Late_blight',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Grape___Black_rot',\n",
        "    '/content/drive/MyDrive/extracted_without_augmentation/Plant_leave_diseases_dataset_without_augmentation/Grape___healthy',\n",
        "\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Apple___Apple_scab',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Apple___healthy',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Corn___healthy',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Corn___Common_rust',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Pepper,_bell___Bacterial_spot',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Potato___healthy',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Potato___Early_blight',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Pepper,_bell___healthy',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Tomato___healthy',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Tomato___Late_blight',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Grape___Black_rot',\n",
        "    '/content/drive/MyDrive/extracted_with_augmentation/Plant_leave_diseases_dataset_with_augmentation/Grape___healthy'\n",
        "\n",
        "]\n",
        "\n",
        "all_features, all_labels = load_all_features_and_labels(folder_paths)\n",
        "\n",
        "if not all_features:\n",
        "    print(\"No features extracted. Check the dataset and feature extraction process.\")\n",
        "\n",
        "# train the knn model and get the knn model and the scaler model\n",
        "knn_model, scaler = train_knn_model(all_features, all_labels)\n",
        "\n",
        "# Save the trained model and scaler\n",
        "save_model_and_scaler(knn_model, scaler)\n"
      ],
      "metadata": {
        "id": "Zp1NPsNVPr0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}